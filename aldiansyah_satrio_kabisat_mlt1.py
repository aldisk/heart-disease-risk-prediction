# -*- coding: utf-8 -*-
"""Aldiansyah Satrio Kabisat_MLT1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I6m4iieZO2Knf0zkOGYyhHrhVSHUWObX
"""

from google.colab import files

files.upload()

!mkdir ~/.kaggle
!mv kaggle.json ~/.kaggle/kaggle.json

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download kamilpytlak/personal-key-indicators-of-heart-disease

!mkdir dataset
!unzip personal-key-indicators-of-heart-disease.zip -d ./dataset

import pandas as pd
import numpy as np

df = pd.read_csv('dataset/2020/heart_2020_cleaned.csv')

"""# Data Analysis"""

df.head(10)

df.info()
print('\n')
print(df.isnull().sum())
print('\n')
print(df.eq(0).sum())

import seaborn as sns
import matplotlib.pyplot as plt

columns_to_plot = [col for col in df.columns if col not in ["BMI", "PhysicalHealth", "MentalHealth"]]

# Plotting
fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(18, 30))

for i, col in enumerate(columns_to_plot):
    sns.countplot(data=df, x=col, ax=axes[i//3, i%3], order=df[col].value_counts().index)  # Specify order of x-axis labels
    axes[i//3, i%3].set_title(f'Distribution of {col}')
    axes[i//3, i%3].set_xlabel(col)
    axes[i//3, i%3].set_ylabel('Count')
    axes[i//3, i%3].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

columns_to_plot = ["BMI", "PhysicalHealth", "MentalHealth"]

# Plotting
plt.figure(figsize=(12, 8))
for i, col in enumerate(columns_to_plot):
    plt.subplot(2, 2, i+1)
    sns.violinplot(data=df, y=col)
    plt.title(f'Violin Plot of {col}')
    plt.ylabel(col)
    plt.xlabel('Density')

plt.tight_layout()
plt.show()

print(df['HeartDisease'].value_counts())

"""Data Kategorikal dan Ordinal umumnya memiliki distribusi yang menunjuk ke satu arah, Hal ini dapat disebabkan karena distribusi kelas target yang kurang seimbang ataupun terdapat kecenderungan lainnya yang belum diketahui

Data kontinu umumnya memiliki distribusi yang cenderung mendekati normal namun terdapat banyak cukup banyak noise

------------------------------------------

Dengan memperhatikan hal tersebut perlu dilakukan penangangan terhadap imbalanced class tersebut. Dalam kasus ini akan digunakan undersampling mengingat data class negatif sudah berjumlah cukup banyak

# Oversampling
"""

from imblearn.over_sampling import SMOTENC

df_processed = df.copy()

# Oversampling with SMOTE
smote = SMOTENC(categorical_features = [1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16], random_state=42)
X_resampled, y_resampled = smote.fit_resample(df_processed.drop(columns=['HeartDisease']), df_processed['HeartDisease'])

df_resampled = pd.concat([pd.DataFrame(X_resampled, columns=df.columns[1:]), pd.Series(y_resampled, name='HeartDisease')], axis=1)

print(df_resampled['HeartDisease'].value_counts())

df_resampled.isnull().sum()

"""Seluruh Data telah diproses dan di encode. Normalisasi tidak dilakukan karena akan menggunakan DecisionTree yang tidak sensitif terhadap Normalisasi

# Encoding
"""

df_encoded = df_resampled.copy()

binary = ['HeartDisease', 'Smoking', 'AlcoholDrinking', 'Stroke', 'DiffWalking', 'PhysicalActivity', 'KidneyDisease', 'Asthma', 'SkinCancer']

for col in binary:
  df_encoded[col] = df_encoded[col].map({'No': 0, 'Yes': 1})

age_mapping = {
    '18-24': 1,
    '25-29': 2,
    '30-34': 3,
    '35-39': 4,
    '40-44': 5,
    '45-49': 6,
    '50-54': 7,
    '55-59': 8,
    '60-64': 9,
    '65-69': 10,
    '70-74': 11,
    '75-79': 12,
    '80 or older': 13
}

diabetes_mapping = {
    'No': 0,
    'No, borderline diabetes': 1,
    'Yes': 2,
    'Yes (during pregnancy)': 2,
}

health_mapping = {
    'Poor': 1,
    'Fair': 2,
    'Good': 3,
    'Very good': 4,
    'Excellent': 5
}

race_mapping = {
    'White': 1,
    'Hispanic': 2,
    'Black': 3,
    'Asian': 4,
    'American Indian/Alaskan Native': 5,
    'Other': 6
}

df_encoded['Sex'] = df_encoded['Sex'].map({'Female': 0, 'Male': 1})
df_encoded['AgeCategory'] = df_encoded['AgeCategory'].map(age_mapping)
df_encoded['Diabetic'] = df_encoded['Diabetic'].map(diabetes_mapping)
df_encoded['GenHealth'] = df_encoded['GenHealth'].map(health_mapping)
df_encoded['Race'] = df_encoded['Race'].map(race_mapping)

df_encoded.head(10)

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score

# Split data into features (X) and target variable (y)
X = df_encoded.drop(columns=['HeartDisease'])
y = df_encoded['HeartDisease']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

X_train.isnull().sum()

y

"""# Modelling (Decision Tree)"""

clf = DecisionTreeClassifier(criterion = 'entropy', splitter = 'best', min_samples_split=6, max_features='log2')
clf.fit(X_train, y_train)

# Make predictions
y_pred = clf.predict(X_test)

# Evaluate the model
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Accuracy Score:", accuracy_score(y_test, y_pred))

"""# Modelling (Random Forest)"""

from sklearn.ensemble import RandomForestClassifier

# Instantiate RandomForestClassifier with optional hyperparameters
rfc = RandomForestClassifier(criterion = 'entropy', n_estimators=50, min_samples_split=2)

# Fit the model to the training data
rfc.fit(X_train, y_train)

# Predict the target variable for the test data
y_pred_rfc = rfc.predict(X_test)

# Evaluate the model
print("Classification Report:")
print(classification_report(y_test, y_pred_rfc))
print("Accuracy Score:", accuracy_score(y_test, y_pred_rfc))

"""Dari hasil ujicoba diatas didapatkan bahwa algoritma Random Forest lebih baik dalam memperkirakan resiko seseorang terkena penyakit jantung. Akurasi dari kedua algoritma belum cukup baik untuk dijadikan sebagai sistem deteksi utama penyakit, meskipun demikian, kedua algoritma dapat digunakan sebagai sistem pembantu untuk menseleksi orang dengan resiko penyakit jantung secara cepat. Selain itu dikarenakan tingkat explainability dari Decision Tree dan Random Forest tinggi dibandingkan metode ML lainnya, knowledge yang didapatkan dari kedua metode diatas dapat diaplikasikan secara langsung untuk pengembangan metode deteksi penyakit jantung lainnya dengan basis statistika ataupun untuk memahami alur kerja algoritma untuk meningkatkan kepercayaan terhadap model yang telah dibuat"""